---
layout: post
title: Binder 跨进程通信底层实现
key: 20171204
tags: Binder IPC Android
---

### <i class="fa fa-rebel fa-1x" aria-hidden="true"></i>  Binder IPC 原理
##### <i class="fa fa-star" aria-hidden="true"></i> IPC 概念
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
IPC(Inter-Process Communication)，意为进程间通信，通常是指两个进程之间进行数据交换的过程；Android 不同应用在没有设置 shareUid 的情况下，运行在不同的进程之间，不同应用之间需要进行数据交换的过程属于 IPC 的一种。
##### <i class="fa fa-star" aria-hidden="true"></i> 其他 IPC
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
除了 Binder ，Linux 下还有以下几种 IPC

+ 共享内存
+ 套接字
+ 匿名管道
+ 命名管道
+ 消息队里
+ 信号量
+ 信号

有兴趣的同学可以去了解下以上 IPC 的原理。

##### <i class="fa fa-star" aria-hidden="true"></i> Binder IPC
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
IPC 原理图

![](/assets/binder/kernel.png)

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
每个进程都分为用户空间和内核空间，用户空间的数据是不能跟共享的，而内核空间却是可以共享的，客户端进程把需要交换的数据写入内核层，服务端进程再从内核中获取数据以此实现跨进程通信；Binder IPC 是通过 Binder 驱动来实现的，Binder 驱动与其他字符驱动原理一样，在系统启动的时候，会在 dev 目录下创建 binder 驱动，不同的进程通过访问和操作 binder 驱动实现用户空间和内核空间数据交互。
### <i class="fa fa-rebel fa-1x" aria-hidden="true"></i>  Binder 架构
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
Binder 采用 C/S 架构，C 代表客户端进程，S 代表服务端进程，客户端和服务端建立连接需要用到 Binder 的守护进程 ServiceManager 进程，ServiceManager 作为所有 Binder 服务的大管家，所有服务(<font color="red">匿名 binder 除外</font>)都需要向ServiceManager大管家注册,客户端进程通过服务大管家的 getService("服务名称") 获取服务，至此客户端持有服务端的 binder 引用，从而能间接实现数据交互，架构图如下：

![](/assets/binder/service.png)

### <i class="fa fa-rebel fa-1x" aria-hidden="true"></i> Binder 实现细节
##### <i class="fa fa-star" aria-hidden="true"></i> Binder 驱动
1.binder 驱动注册<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
binder 驱动跟其他 linux 驱动一样，binder驱动在以misc设备进行注册，作为虚拟字符设备，没有直接操作硬件，只是对设备内存的处理。通过初始化方法binder_init()来实现
```c
static int __init binder_init(void)
{
	int ret;

	binder_deferred_workqueue = create_singlethread_workqueue("binder");
	if (!binder_deferred_workqueue)
		return -ENOMEM;

	binder_debugfs_dir_entry_root = debugfs_create_dir("binder", NULL);
	if (binder_debugfs_dir_entry_root)
		binder_debugfs_dir_entry_proc = debugfs_create_dir("proc",
						 binder_debugfs_dir_entry_root);
	ret = misc_register(&binder_miscdev);
	return ret;
}
```
注册设备的时候需要传入binder_miscdev结构体，包涵驱动名称、小版本号以及操作方法
```c
static struct miscdevice binder_miscdev = {
	.minor = MISC_DYNAMIC_MINOR,
	.name = "binder",
	.fops = &binder_fops
};
```
2.打开驱动<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
至此，进入操作驱动的一般流程，第一步就是通过 open 驱动，所以 binder 驱动需要提供一个可供外部打开的方法
```c
static int binder_open(struct inode *nodp, struct file *filp)
{
	struct binder_proc *proc;

	binder_debug(BINDER_DEBUG_OPEN_CLOSE, "binder_open: %d:%d\n",
		     current->group_leader->pid, current->pid);

	proc = kzalloc(sizeof(*proc), GFP_KERNEL);
	if (proc == NULL)
		return -ENOMEM;
	get_task_struct(current);
	proc->tsk = current;
	INIT_LIST_HEAD(&proc->todo);
	init_waitqueue_head(&proc->wait);
	proc->default_priority = task_nice(current);

	binder_lock(__func__);

	binder_stats_created(BINDER_STAT_PROC);
	hlist_add_head(&proc->proc_node, &binder_procs);
	proc->pid = current->group_leader->pid;
	INIT_LIST_HEAD(&proc->delivered_death);
	filp->private_data = proc;
	binder_unlock(__func__);
	return 0;
}
```
3.映射内存<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
将虚拟内存地址映射到物理内存地址
```c
static int binder_mmap(struct file *filp, struct vm_area_struct *vma)
{
	int ret;
	struct vm_struct *area;
	struct binder_proc *proc = filp->private_data;
	const char *failure_string;
	struct binder_buffer *buffer;

	if (proc->tsk != current)
		return -EINVAL;

	if ((vma->vm_end - vma->vm_start) > SZ_4M)
		vma->vm_end = vma->vm_start + SZ_4M;

	if (vma->vm_flags & FORBIDDEN_MMAP_FLAGS) {
		ret = -EPERM;
		failure_string = "bad vm_flags";
		goto err_bad_arg;
	}
	vma->vm_flags = (vma->vm_flags | VM_DONTCOPY) & ~VM_MAYWRITE;

	mutex_lock(&binder_mmap_lock);
	if (proc->buffer) {
		ret = -EBUSY;
		failure_string = "already mapped";
		goto err_already_mapped;
	}

	area = get_vm_area(vma->vm_end - vma->vm_start, VM_IOREMAP);
	if (area == NULL) {
		ret = -ENOMEM;
		failure_string = "get_vm_area";
		goto err_get_vm_area_failed;
	}
	proc->buffer = area->addr;
	proc->user_buffer_offset = vma->vm_start - (uintptr_t)proc->buffer;
	mutex_unlock(&binder_mmap_lock);
	return ret;
}
```
4.操作驱动设备<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
真正执行数据交互的方法是通过 binder_ioctl() 这个方法
```c
static long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
{
	int ret;
	struct binder_proc *proc = filp->private_data;
	struct binder_thread *thread;
	unsigned int size = _IOC_SIZE(cmd);
	void __user *ubuf = (void __user *)arg;

	ret = wait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error < 2);
	if (ret)
		goto err_unlocked;
	binder_lock(__func__);
	thread = binder_get_thread(proc);
	switch (cmd) {
	case BINDER_WRITE_READ:
		ret = binder_ioctl_write_read(filp, cmd, arg, thread);
		if (ret)
			goto err;
		break;
	case BINDER_SET_MAX_THREADS:
		if (copy_from_user(&proc->max_threads, ubuf, sizeof(proc->max_threads))) {
			ret = -EINVAL;
			goto err;
		}
		break;
	case BINDER_SET_CONTEXT_MGR:
		ret = binder_ioctl_set_ctx_mgr(filp);
		if (ret)
			goto err;
		break;
	case BINDER_THREAD_EXIT:
		binder_debug(BINDER_DEBUG_THREADS, "%d:%d exit\n",
			     proc->pid, thread->pid);
		binder_free_thread(proc, thread);
		thread = NULL;
		break;
	default:
		ret = -EINVAL;
		goto err;
	}
	ret = 0;
	return ret;
}
```
当收到BINDER_WRITE_READ协议时，表示需要传递数据；BINDER_SET_CONTEXT_MGR 代表设置为 Binder 服务上下文，即我们的守护进程需要通过此协议来设置。

##### <i class="fa fa-star" aria-hidden="true"></i> Binder 守护进程
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
守护进程顾名思义此进程的作用是在守护 Binder 服务的一个进程，往往守护进程都是在设备启动的时候开始执行，直至设备关机。Binder 的守护进程名为 ServiceManager 进程，在 Linux 的启动配置项中有一项就是启动 ServiceManager 进程，ServiceManager 自动启动之后首先会进入main 函数
```c
int main(int argc, char** argv)
{
    struct binder_state *bs;
    union selinux_callback cb;
    char *driver;

    if (argc > 1) {
        driver = argv[1];
    } else {
        driver = "/dev/binder";
    }

    bs = binder_open(driver, 128*1024);

    if (binder_become_context_manager(bs)) {
        ALOGE("cannot become context manager (%s)\n", strerror(errno));
        return -1;
    }

    cb.func_audit = audit_callback;
    selinux_set_callback(SELINUX_CB_AUDIT, cb);
    cb.func_log = selinux_log_callback;
    selinux_set_callback(SELINUX_CB_LOG, cb);

#ifdef VENDORSERVICEMANAGER
    sehandle = selinux_android_vendor_service_context_handle();
#else
    sehandle = selinux_android_service_context_handle();
#endif
    selinux_status_open(true);


    if (getcon(&service_manager_context) != 0) {
        ALOGE("SELinux: Failed to acquire service_manager context. Aborting.\n");
        abort();
    }


    binder_loop(bs, svcmgr_handler);

    return 0;
}
```
+ 先打开"/dev/binder"设备，在binder_open里面有正在的 open 操作，同时还有 mmap 操作；
+ 让此进程成为 Binder 服务的大管家
+ 进入循环监听其他服务，包括注册和获取服务

##### <i class="fa fa-star" aria-hidden="true"></i> 注册 Binder 服务
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
注册服务是通过 ServiceManager 的do_add_service()方法向底层驱动申请一段服务端相关的内存地址，并在ServiceManager中保留服务端的相关引用（此过程比较复杂，可自行查阅底层相关源码）

##### <i class="fa fa-star" aria-hidden="true"></i> 获取 Binder 服务
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
既然ServiceManager中保留服务端的相关引用，那么获取服务就相对比较简单，ServiceManager 的 do_find_service()方法，这里需要说明一点，虽然ServiceManager保留了服务端相关信息，但却不能直接拿来使用，因为服务端有可能对于多个客户端，所以还需要向底层驱动进行区分，确保C/S 是一一对应。

### <i class="fa fa-rebel fa-1x" aria-hidden="true"></i> 总结
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
本篇主要介绍 Binder IPC 的底层原理，Binder 的架构流程，Binder 守护进程 ServiceManager,使用 Binder 需要先向 ServiceManager 中注册服务；通过本篇内容，是为了更好的理解上层 Binder 是如何工作的，在后面的文章中会讲应用层对 Binder 的使用。

